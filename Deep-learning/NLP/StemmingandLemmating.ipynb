{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229f4cd4-8379-46af-b276-1d443e503aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cd67a4-7bdd-4c74-a12c-f7ecde7103fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0a7196-ddb4-461d-9bd0-d19813327c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8abdb1-4d8f-4e15-8f75-6df0b41a681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history----->histori\n",
      "eating----->eat\n",
      "language----->languag\n",
      "python----->python\n",
      "library----->librari\n",
      "student----->student\n",
      "computer----->comput\n",
      "science----->scienc\n"
     ]
    }
   ],
   "source": [
    "words = [\"history\", \"eating\", \"language\", \"python\", \"library\", \"student\", \"computer\", \"science\"]\n",
    "\n",
    "# this type of steeming sometimes give no sense meaaning words like history to histori\n",
    "for word in words:\n",
    "    print( word + \"----->\" + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4718919d-2b0a-44c9-afb8-535fce549f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we use lancaster stemming\n",
    "# same all but use import LancasterStemmer\n",
    "\n",
    "# another is RegexpStemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "regex = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "regex.stem(\"eating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "719a2edb-8258-48b6-9cab-27fcba905243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingplay'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.stem(\"ingplaying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f2bd752-9709-4daa-bd2e-9f34f1b5df9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now if we remove $ then it will remove all ing\n",
    "regex = RegexpStemmer('ing|s$|e$|able$', min=4)\n",
    "regex.stem(\"ingplaying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450a1357-afb8-4455-9e61-c721c6f3c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history----->histori\n",
      "eating----->eat\n",
      "language----->languag\n",
      "python----->python\n",
      "library----->librari\n",
      "student----->student\n",
      "computer----->comput\n",
      "science----->scienc\n"
     ]
    }
   ],
   "source": [
    "# SnowballStemmer    perform slighlty better\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english', ignore_stopwords=True)\n",
    "for word in words:\n",
    "    print( word + \"----->\" + snowball.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc95ef7e-58f0-4215-9aab-8a8321003054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\manje\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# now in stemming some words meaning chamged so lemmeting fix this\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer =WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "802fe3f4-3a7a-43b9-9d0a-15a72d218805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history---> history\n",
      "eating---> eating\n",
      "language---> language\n",
      "python---> python\n",
      "library---> library\n",
      "student---> student\n",
      "computer---> computer\n",
      "science---> science\n"
     ]
    }
   ],
   "source": [
    "# by deafult is take lemmatize(word, pos='n')  as noun\n",
    "for word in words:\n",
    "    print(word + \"---> \" + lemmatizer.lemmatize(word))\n",
    "\n",
    "# Stemming -> sentiment anaylsis\n",
    "# chatbot  ->  lemmiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5b7a9-625c-4126-b866-1c3668e9459b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2eae7-162d-412e-9b6d-db36a666c7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
